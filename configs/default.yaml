# Default configuration for RAGMint pipeline

retriever:
  type: "faiss"          # Options: faiss, chroma, elasticsearch
  top_k: 5

reranker:
  type: "mmr"            # Options: mmr, crossencoder
  lambda_param: 0.5

chunking:
  chunk_size: 500
  overlap: 100

embeddings:
  backend: "huggingface" # Options: openai, huggingface, dummy
  model: "sentence-transformers/all-MiniLM-L6-v2"

generator:
  type: "openai"         # Options: openai, llama, mock
  model: "gpt-4-turbo"
  temperature: 0.2
  max_tokens: 512

evaluation:
  metrics: ["faithfulness", "latency", "bleu", "rouge_l"]

optimization:
  method: "grid"         # Options: grid, random, bayesian
  max_trials: 10

data:
  validation_path: "experiments/validation_qa.json"
  cache_dir: ".ragmint_cache"

logging:
  level: "INFO"
